xlab("Suspect Race") +
ylab("N Stops") +
scale_fill_brewer(type = "qual", palette = "Pastel1", name = "Suspect Arrested") +
labs(title = "Distribution of Arrest Status, By Suspect Race")
# arrests by race, stacked
ggplot(data = sqf_data, aes(x = fct_rev(fct_infreq(suspect_race_description)), fill = factor(suspect_arrested_flag))) +
geom_bar(position = "fill") +
coord_flip() +
scale_y_continuous(labels = scales::percent) +
theme_minimal() +
xlab("Suspect Race") +
ylab("% Stops") +
scale_fill_brewer(type = "qual", palette = "Pastel1", name = "Suspect Arrested") +
labs(title = "Distribution of Arrest Status, By Suspect Race")
# arrests by suspected crime description, unstacked
ggplot(data = sqf_data, aes(x = fct_rev(fct_infreq(suspected_crime_description)), fill = factor(suspect_arrested_flag))) +
geom_bar() +
coord_flip() +
theme_minimal() +
xlab("Suspected Crime") +
ylab("N Stops") +
scale_fill_brewer(type = "qual", palette = "Pastel1", name = "Suspect Arrested") +
labs(title = "Distribution of Arrest Status, By Suspected Crime")
# arrests by suspected crime description, stacked
ggplot(data = sqf_data, aes(x = suspected_crime_description, fill = factor(suspect_arrested_flag))) +
geom_bar(position = "fill") +
coord_flip() +
scale_y_continuous(labels = scales::percent) +
theme_minimal() +
xlab("Suspected Crime") +
ylab("% Stops") +
scale_fill_brewer(type = "qual", palette = "Pastel1", name = "Suspect Arrested") +
labs(title = "Distribution of Arrest Status, By Suspect Crime")
# heatmap of arrests by time of day and borough
ggplot(
sqf_data %>%
group_by(stop_location_boro_name, time_of_day) %>%
summarise(
percent_arrested = mean(suspect_arrested_flag, na.rm = TRUE) * 100,
.groups = "drop"
),
aes(
x = time_of_day,
y = stop_location_boro_name,
fill = percent_arrested
)
) +
geom_tile(color = "white") +
scale_fill_viridis_c(name = "Arrest Rate (%)") +
labs(
title = "Heat Map of Arrest Rates",
x = "Time of Day",
y = "Borough"
) +
theme_minimal()
# heatmap of arrests by issuing officer rank and suspect race
ggplot(
sqf_data %>%
group_by(issuing_officer_rank, suspect_race_description) %>%
summarise(
percent_arrested = mean(suspect_arrested_flag, na.rm = TRUE) * 100,
.groups = "drop"
),
aes(
x = issuing_officer_rank,
y = suspect_race_description,
fill = percent_arrested
)
) +
geom_tile(color = "white") +
scale_fill_viridis_c(name = "Arrest Rate (%)") +
labs(
title = "Heat Map of Arrest Rates",
x = "Officer in Uniform",
y = "Suspect Race"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1)
)
# drop 7 observations which have incorrect spatial info
sqf_data <- sqf_data %>%
filter(stop_location_x > 0)
dim(sqf_data)
# make spatial object for mapping
sqf_data_sf <- st_as_sf(sqf_data,
coords = c("stop_location_x", "stop_location_y"),
crs = 2263)  #  crs for New York (EPSG:2263)
# load in nta-level shapefile
remotes::install_github("mfherman/nycgeo")
library(nycgeo)
nyc_tract_shp <- nycgeo::nyc_boundaries(geography = "tract", add_acs_data = TRUE)
# check crs
st_crs(nyc_tract_shp)$epsg
# plot data onto shapefile by arrest status
ggplot() +
geom_sf(data = nyc_tract_shp, fill = "lightblue", color = "black", size = 0.3) +
geom_sf(data = sqf_data_sf, aes(color = as.factor(suspect_arrested_flag)), size = 0.7) +
scale_color_manual(values = c("red", "seagreen"),
labels = c("Arrested", "Not Arrested")) +
theme_minimal() +
labs(title = "NYC Police Stops by Arrest Status") +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5),
legend.title = element_blank())
# join datasets to assign each stop to a tract
sqf_data_sf <- st_join(sqf_data_sf, nyc_tract_shp)
dim(sqf_data_sf)
# aggregate to tract level
sqf_data_sf_tract_level <- sqf_data_sf %>%
filter(!is.na(geoid)) %>%
group_by(geoid) %>%
summarize(pc_arrest = (sum(suspect_arrested_flag) / n()) * 100)
# join with shp for mapping
sqf_data_sf_tract_level <- nyc_tract_shp %>%
st_join(sqf_data_sf_tract_level, by = "geoid")
ggplot() +
geom_sf(data = sqf_data_sf_tract_level, aes(fill = pc_arrest), color = "black", size = 0.3) +
scale_fill_viridis_c(
name = "% Stops Ending in Arrest",
option = "inferno",
na.value = "white"
) +
theme_void() +
labs(title = "Percentage of Stops Ending in Arrest by NYC Census Tract")
# we first create the new variables in the shapefile for ease of plotting
nyc_tract_shp <- nyc_tract_shp %>%
mutate(pc_pop_black_est = (pop_black_est / pop_total_est) * 100,
pc_pop_hisp_est = (pop_hisp_est / pop_total_est) * 100,
pc_pop_asian_est = (pop_asian_est / pop_total_est) * 100,
pc_pop_ba_above_est = (pop_ba_above_est / pop_total_est) * 100,
pc_pop_inpov_est = (pop_inpov_est / pop_total_est) * 100
)
# non hispanic black
ggplot(nyc_tract_shp) +
geom_sf(aes(fill = pc_pop_black_est)) +
scale_fill_viridis_c(
name = "Non-Hispanic Black % Total Population",
option = "inferno"
) +
theme_void() +
labs(title = "Non-Hispanic Black Population by Census Tract, ACS 2013-2017")
# hispanic any
ggplot(nyc_tract_shp) +
geom_sf(aes(fill = pc_pop_hisp_est)) +
scale_fill_viridis_c(
name = "Hispanic Any Race % Total Population",
option = "inferno"
) +
theme_void() +
labs(title = "Hispanic Any Race Population by Census Tract, ACS 2013-2017")
# non
ggplot(nyc_tract_shp) +
geom_sf(aes(fill = pc_pop_asian_est)) +
scale_fill_viridis_c(
name = "Non-hispanic Asian % Total Population",
option = "inferno"
) +
theme_void() +
labs(title = "Non-hispanic Asian  Population by Census Tract, ACS 2013-2017")
# pop age 25 years or older with at least bachelors degree
ggplot(nyc_tract_shp) +
geom_sf(aes(fill = pc_pop_ba_above_est)) +
scale_fill_viridis_c(
name = "% Population Aged >= 25 with at Least Bachelors Degree",
option = "inferno"
) +
theme_void() +
labs(title = "% Population Aged >= 25 with at least a Bachelor's Degree by Census Tract, ACS 2013-2017")
# income below pov
# pop age 25 years or older with at least bachelors degree
ggplot(nyc_tract_shp) +
geom_sf(aes(fill = pc_pop_inpov_est)) +
scale_fill_viridis_c(
name = "% Population With Income Below Poverty Line",
option = "inferno"
) +
theme_void() +
labs(title = "% Population with Income Below Poverty Line, ACS 2013-2017")
# now we create the new variables in the sqf_data_sf object, before merging as appropriate by stop_id into the original data
sqf_data_sf <- sqf_data_sf %>%
mutate(pc_pop_black_est = (pop_black_est / pop_total_est) * 100,
pc_pop_hisp_est = (pop_hisp_est / pop_total_est) * 100,
pc_pop_asian_est = (pop_asian_est / pop_total_est) * 100,
pc_pop_ba_above_est = (pop_ba_above_est / pop_total_est) * 100,
pc_pop_inpov_est = (pop_inpov_est / pop_total_est) * 100
)
# check current dim
dim(sqf_data)
sqf_data <- sqf_data %>%
# left join selected spatial features from the sf object into sqf_data
left_join(sqf_data_sf %>% select(stop_id, pc_pop_ba_above_est, pc_pop_inpov_est, pc_pop_asian_est, pc_pop_hisp_est, pc_pop_black_est), by = "stop_id") %>%
# drop x,y coords and geometry as we use census tract for spatial info
select(-c("stop_location_x", "stop_location_y", "geometry")) %>%
# drop obs with missing values in these spatial features
filter(!if_any(everything(), is.na))
# check new dim
dim(sqf_data)
# set seed for reproducibility
set.seed(1)
# set y and X matrix
y <- sqf_data$suspect_arrested_flag
X <- model.matrix(~ . - suspect_arrested_flag - stop_id -search_basis_incidental_to_arrest_flag, data = sqf_data)
# perform train-test split
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
y_train <- y[train_index]
y_test <- y[-train_index]
X_train <- X[train_index,]
X_test <- X[-train_index, ]
# print lengths and dimensions
cat("Length of y_train:", length(y_train), "\n")
cat("Length of y_test:", length(y_test), "\n")
cat("Dimensions of X_train:", dim(X_train), "\n")
cat("Dimensions of X_test:", dim(X_test), "\n")
# check balance of y
print(table(y_train))
print(table(y_test))
# set x subset, removing anything that is/might be realized during the stop
X_subset <- X[, !grepl("^(search|physical_force|.*eye_color|.*hair_color)", colnames(X)) &
!colnames(X) %in% c("frisked_flag", "firearm_flag", "knife_cutter_flag",
"other_weapon_flag", "weapon_found_flag", "other_contraband_flag")]
# perform train-test split
X_train_subset <- X_subset[train_index, ]
X_test_subset <- X_subset[-train_index, ]
cat("Dimensions of X_train_subset:", dim(X_train_subset), "\n")
cat("Dimensions of X_test_subset:", dim(X_test_subset), "\n")
# subset training data for validation split
n_train <- nrow(X_train)
id_split <- sample(1:n_train, floor(0.5 * n_train))
# split into training and validation sets
X_train_subset_final <- X_train_subset[id_split, ]
y_train_final <- y_train[id_split]
X_val_subset <- X_train_subset[-id_split, ]
y_val <- y_train[-id_split]
# print dimensions
cat("dimensions of X_train_final:", dim(X_train_subset_final), "\n")
cat("dimensions of y_train_final:", length(y_train_final), "\n")
cat("dimensions of X_val:", dim(X_val_subset), "\n")
cat("dimensions of y_val:", length(y_val), "\n")
# Set X_logit, removing unwanted columns based on the patterns
X_logit <- X_subset[, !grepl("^(supervising_officer_rank)", colnames(X_subset))]
# perform train-test split on X_logit
X_train_logit <- X_logit[train_index, ]
X_test_logit <- X_logit[-train_index, ]
# print lengths and dimensions
cat("Dimensions of X_train_logit:", dim(X_train_logit), "\n")
cat("Dimensions of X_test_subset:", dim(X_test_logit), "\n")
# glm requires dataframes as arguments
X_train_logit_df <- as.data.frame(X_train_logit)
X_test_logit_df <- as.data.frame(X_test_logit)
# full logit model in training data
logit <- glm(y_train ~ ., data = X_train_logit_df, family = binomial(logit))
# get fitted probabilities using trained model on test data
logit_predict <- as.numeric(predict(logit, newdata = X_test_logit_df, type = "response"))
# convert probabilities to class predictions using a threshold of 0.5
logit_y_hat <- ifelse(logit_predict > 0.5, 1, 0)
# inspect class balance of predicted classes
table(logit_y_hat)
# define a function to generate and plot confusion matrix
generate_cm <- function(true, predicted, title) {
# gen confusion matrix as a data frame
cm <- as.data.frame(table(True = true, Predicted = predicted)) %>%
group_by(Predicted) %>%
mutate(Predicted_pct = Freq / sum(Freq))
# print cm
print(cm)
# plot cm
plot <- ggplot(data = cm, mapping = aes(x = ordered(True, c(1, 0)), y = Predicted, fill = Predicted_pct)) +
geom_tile() +
geom_text(aes(label = round(Predicted_pct, 2)), color = 'white') +
scale_fill_gradient(low = "blue", high = "red", name = "Rel. Freq.") +
xlab("True") +
ylab("Predicted") +
labs(title = title) +
theme_minimal()
# print plot
print(plot)
}
# plot confusion matrix for logistic regression with all variables
generate_cm(y_test, logit_y_hat, "Confusion Matrix for Logistic Regression")
# compute ROC and AUC
logit_roc <- roc(response = y_test, predictor = logit_predict, quiet = TRUE)
logit_auc <- round(auc(logit_roc), 4)
cat("AUC for the logit model", logit_auc, "\n")
# Install and load required packages
if (!require("pacman")) install.packages("pacman")
library(pacman)
p_load(readxl, dplyr, ggplot2, knitr, lubridate, tidyr, sf, httr, caret, glmnet, stringr, remotes, RColorBrewer, viridis, scales, classInt, forcats, pROC, randomForest)
# get raw content of the file
response <- GET("https://raw.githubusercontent.com/rrachelkane/data-science-group-project/main/data/sqf-2023.xlsx")
# retrieve the .xlsx file
if (status_code(response) == 200) {
# create a temporary file to save the downloaded content
temp_file <- tempfile(fileext = ".xlsx")
# Write the raw content to the temporary file
writeBin(content(response, "raw"), temp_file)
# Read the Excel file from the temporary file
sqf_data <- read_xlsx(temp_file)
# View the first few rows of the data
head(sqf_data)
} else {
stop("Failed to download the file.")
}
# check original dimensions
dim(sqf_data)
# view head
head(sqf_data)
colnames(sqf_data) <- tolower(colnames(sqf_data))
# check
colnames(sqf_data)[1:3]
sqf_data <- sqf_data %>%
select(- c("stop_frisk_date", "record_status_code", "supervising_action_corresponding_activity_log_entry_reviewed", "stop_location_sector_code", "stop_location_apartment", "stop_location_full_address", "stop_location_patrol_boro_name", "stop_location_street_name", "suspect_other_description", "observed_duration_minutes", "stop_duration_minutes", "summons_issued_flag", "supervising_officer_command_code", "issuing_officer_command_code", "stop_location_precinct", "year2", "suspect_arrest_offense"))
# check new dim
dim(sqf_data)
na_cols <- colMeans(is.na(sqf_data)) * 100
na_cols[na_cols > 0]
sqf_data[1:5, "demeanor_of_person_stopped"]
# drop
sqf_data <- sqf_data %>%
select(-("demeanor_of_person_stopped"))
# check new dim
dim(sqf_data)
# get % of nulls, in columns with at least one null
null_cols <- (colMeans(sqf_data == "(null)") * 100)[colMeans(sqf_data == "(null)") * 100 > 0]
# make df for plot
null_cols_df <- data.frame(Feature = names(null_cols), Percentage = null_cols)
dim(null_cols_df)
# order for plot
null_cols_df$Feature <- factor(null_cols_df$Feature,
levels = null_cols_df$Feature[order(null_cols_df$Percentage, decreasing = FALSE)])
# plot
ggplot(null_cols_df, aes(x = Feature, y = Percentage)) +
geom_bar(stat = "identity", fill = "lightblue", color = "darkblue") +
labs(title = "Percentage of (null) Values per Column",
x = "Columns",
y = "Percentage of (null) Values") +
coord_flip() +  # Flip coordinates
theme_minimal()
sqf_data %>%
group_by(ask_for_consent_flg) %>%
summarise(N = n()) %>%
kable()
print(unique(sqf_data$firearm_flag))
sqf_data %>%
group_by(weapon_found_flag, firearm_flag) %>%
summarise(N = n()) %>%
kable()
# note that for the identifying variables related to cops, "yes" entries are indicated unusually
print(unique(sqf_data$id_card_identifies_officer_flag))
print(unique(sqf_data$verbal_identifies_officer_flag))
print(unique(sqf_data$shield_identifies_officer_flag))
# initialize empty vector
null_2 <- c()
# loop through columns
# loop through columns
for (col in names(sqf_data)) {
# Get unique values of the column
unique_values <- unique(sqf_data[[col]])
# Check if unique values are exactly a subset of "Y", "I", "V", "S", and "(null)"
if (all(unique_values %in% c("Y", "I", "V", "S", "(null)")) && length(unique_values) == 2) {
null_2 <- c(null_2, col)  # Add column name to null_2
}
}
# check n of type 2 nulls
length(null_2)
# pre-clean check examples
print(unique(sqf_data$firearm_flag))
print(unique(sqf_data$id_card_identifies_officer_flag))
# replace these nulls with Ns
sqf_data <- sqf_data %>%
mutate(across(all_of(null_2), ~ ifelse(. == "(null)", "N", .)))
# post-clean check examples
print(unique(sqf_data$firearm_flag))
print(unique(sqf_data$id_card_identifies_officer_flag))
# initialize empty vector
null_1 <- c()
# loop through columns
for (col in names(sqf_data)) {
# for columns not in null_2
if (!(col %in% null_2)) {
# if "(null)" is present in the column
if ("(null)" %in% sqf_data[[col]]) {
null_1 <- c(null_1, col)  # add column name to the vector
}
}
}
# check length
length(null_1)
# pre-clean check
print(unique(sqf_data$ask_for_consent_flg))
# replace these with NAs
sqf_data <- sqf_data %>%
mutate(across(all_of(null_1), ~ ifelse(. == "(null)", NA, .)))
# post-clean check
print(unique(sqf_data$ask_for_consent_flg))
# get % of NAs, in columns with at least one NA
na_cols <- (colMeans(is.na(sqf_data)) * 100)[colMeans(is.na(sqf_data)) * 100 > 0]
# make df for plot
na_cols_df <- data.frame(Feature = names(na_cols), Percentage = na_cols)
# order for plot
na_cols_df$Feature <- factor(na_cols_df$Feature,
levels = na_cols_df$Feature[order(na_cols_df$Percentage, decreasing = FALSE)])
# plot
ggplot(na_cols_df, aes(x = Feature, y = Percentage)) +
geom_bar(stat = "identity", fill = "#F8566D", color = "black") +
labs(title = "Percentage of NA Values per Column",
x = "Columns",
y = "Percentage of NA Values") +
coord_flip() +  # Flip coordinates
theme_minimal()
sqf_data <- sqf_data %>%
select(-all_of(names(na_cols[na_cols > 25])))
dim(sqf_data)
sqf_data <- sqf_data %>%
filter(!if_any(everything(), is.na))
dim(sqf_data)
# pre check
print(unique(sqf_data$firearm_flag))
print(unique(sqf_data$id_card_identifies_officer_flag))
# clean Ys and Ns and set as numeric
sqf_data <- sqf_data %>%
mutate(across(
where(~ all(. %in% c("Y", "N", "I", "V", "S"))),
~ as.numeric(ifelse(. %in% c("Y", "I", "V", "S"), 1, 0))
))
# post check
print(unique(sqf_data$firearm_flag))
print(unique(sqf_data$id_card_identifies_officer_flag))
sqf_data <- sqf_data %>%
mutate(
time_of_day = case_when(
str_extract(stop_frisk_time, "^\\d{2}") %in% c("00", "01", "02", "03", "04", "05") ~ "Late Night",
str_extract(stop_frisk_time, "^\\d{2}") %in% c("06", "07", "08", "09", "10", "11") ~ "Morning",
str_extract(stop_frisk_time, "^\\d{2}") %in% c("12", "13", "14", "15", "16", "17") ~ "Afternoon",
str_extract(stop_frisk_time, "^\\d{2}") %in% c("18", "19", "20", "21", "22", "23") ~ "Evening",
TRUE ~ NA_character_
),
time_of_day = factor(time_of_day, levels = c("Late Night", "Morning", "Afternoon", "Evening"))
)
# check
print(table(sqf_data$time_of_day))
# now drop stop frisk time as we will just use time_of_day
sqf_data <- sqf_data %>%
select(-"stop_frisk_time")
# convert character columns to factors, except for stop location x and y
sqf_data <- sqf_data %>%
mutate(across(
.cols = where(is.character) & !c("stop_location_x", "stop_location_y"),
.fns = as.factor
))
# define convert factor to numeric, handling non-numeric entries
convert_to_numeric <- function(x) {
# convert to character to avoid factor levels issues
x <- as.character(x)
# replace non-numeric values with NA (e.g., "unknown", "760", "7.6")
x <- gsub("[^0-9.]", "", x)
# convert to numeric
as.numeric(x)
}
# apply the function to the relevant columns
sqf_data <- sqf_data %>%
mutate(
suspect_reported_age = convert_to_numeric(suspect_reported_age),
suspect_height = convert_to_numeric(suspect_height),
suspect_weight = convert_to_numeric(suspect_weight)
)
# check to make sure successful
summary(sqf_data$suspect_reported_age)
summary(sqf_data$suspect_height)
summary(sqf_data$suspect_weight)
# Function to convert feet.inches to feet
convert_to_feet <- function(feet_inches) {
# Extract feet (integer part)
feet <- floor(feet_inches)
# Get the fractional part
fractional_part <- feet_inches - feet
# Interpret inches based on the fractional part
if (fractional_part == 0) {
# No fractional part means no additional inches
inches <- 0
} else {
# Convert fractional part to a string to check its length
fractional_str <- as.character(fractional_part)
if (grepl("\\.\\d$", fractional_str)) {
# Case like `.1`: Single digit after decimal -> 1, 2, ..., 9 inches
inches <- fractional_part * 10
} else if (grepl("\\.\\d0$", fractional_str)) {
# Case like `.10`, `.20`, etc.: Two digits ending in `0` -> 10, 20, etc. inches
inches <- fractional_part * 100
} else {
# Case like `.11`, `.12`, etc.: Two digits not ending in `0` -> Exact inches
inches <- fractional_part * 100
}
}
# Validate inches (should be between 0 and 11)
if (inches < 0 || inches > 11.9) {
warning(paste("Invalid height input:", feet_inches, "- Inches must be between 0 and 11.9. Returning NA."))
return(NA) # We have no NAs, so inches were extracted correctly.
}
# Convert inches to feet
inches_in_feet <- inches / 12
# Return total height in feet
return(feet + inches_in_feet)
}
# Apply the conversion function to the 'suspect_height' column
sqf_data$suspect_height_feet <- sapply(sqf_data$suspect_height, convert_to_feet)
# Check the result
tail(sqf_data[, c("suspect_height", "suspect_height_feet")])
sqf_data$suspect_height <- sqf_data$suspect_height_feet
#drop suspect
sqf_data <- sqf_data %>% dplyr::select(-suspect_height_feet)
head(sqf_data)
