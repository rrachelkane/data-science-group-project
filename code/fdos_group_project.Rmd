---
title: 'Final Project: X Prediction'
author: "Mira√ß Arda Balaban, Rachel Kane, Lucas Mordue, Gretchen Moulton"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    number_sections: true
    toc_float: true
    df-print: paged
    fig-width: 9
    fig-height: 6
    page-layout: full
---

```{r}
# Install and load required packages
if (!require("pacman")) install.packages("pacman")
library(pacman)

p_load(readxl, dplyr, ggplot2, knitr, lubridate, tidyr, sf, httr)
```

# Abstract

The goal of our project is to predict Y. *edit, include key findings*

# Introduction

* **Target variable:**

* **Motivation:** *edit here re relevance, cite some literature*

* **Relevant features:** *edit*

* **Methods:** *edit*

# Data Description

 We use the [New York Police Department Stop, Question and Frisk Data](https://www.nyc.gov/site/nypd/stats/reports-analysis/stopfrisk.page) from 2023.

* How data is collected & what universe is/is not observed

* Temporal and spatial span.

The data has 16971 observations and 82 features, as shown below.

We begin the project by setting up file paths and importing the data.

```{r}
# get raw content of the file 
response <- GET("https://raw.githubusercontent.com/rrachelkane/data-science-group-project/main/data/sqf-2023.xlsx")

# retrieve the .xlsx file
if (status_code(response) == 200) {
  # Create a temporary file to save the downloaded content
  temp_file <- tempfile(fileext = ".xlsx")
  
  # Write the raw content to the temporary file
  writeBin(content(response, "raw"), temp_file)
  
  # Read the Excel file from the temporary file
  sqf_data <- read_xlsx(temp_file)
  
  # View the first few rows of the data
  head(sqf_data)
} else {
  stop("Failed to download the file.")
}

# Check original dimensions
dim(sqf_data)

# View head
head(sqf_data)
```

# Data Cleaning

## Column Names

First, we change column names from strictly upper case to strictly lower case, because it's cuter.

```{r}
colnames(sqf_data) <- tolower(colnames(sqf_data))

# check
colnames(sqf_data)[1:3]
```

## Missing Values 

First, we note that there are only two features with any instance of an `NA` value.

```{r}
na_cols <- colMeans(is.na(sqf_data)) * 100 
na_cols[na_cols > 0]
```

*edit* The process generating the missingness of `demeanor_of_person_stopped` is unclear. Imputation of this would be difficult. Secondly, `stop_location_street_name` is not required for prediction in our case as we have other spatial measures. We drop both of these features.

```{r}
# drop features
sqf_data <- sqf_data %>% 
  select(-c("demeanor_of_person_stopped", "stop_location_street_name"))

# check new dim
dim(sqf_data)
```

However, there are many observations in the data with values == `(null)` across different columns.

```{r}
# get % of nulls in columns with at least one null
null_cols <- (colMeans(sqf_data == "(null)") * 100)[colMeans(sqf_data == "(null)") * 100 > 0]

# make df for plot
null_cols_df <- data.frame(Feature = names(null_cols), Percentage = null_cols)

# order for plot
null_cols_df$Feature <- factor(null_cols_df$Feature, 
                              levels = null_cols_df$Feature[order(null_cols_df$Percentage, decreasing = FALSE)])

# plot
ggplot(null_cols_df, aes(x = Feature, y = Percentage)) +
  geom_bar(stat = "identity", fill = "lightblue", color = "darkblue") +
  labs(title = "Percentage of (null) Values per Feature", 
       x = "Features", 
       y = "Percentage of (null) Values") +
  coord_flip() +  # Flip coordinates
  theme_minimal()
```

Note, however, that not all of these `(null)` observations are equivalent:

* in some columns - particularly those with lower percentages of `(null)` values, `(null)` means the data are **genuinely effectively `NA`**, as there are instances of both "Y" and "N" (for binary variable for example), alongside `(null)`.

```{r}
sqf_data %>% 
  group_by(ask_for_consent_flg) %>% 
  summarise(N = n()) %>% 
  kable()
```

* whereas in other cases, the `null` values are, confusingly, actually used as "N".

```{r}
print(unique(sqf_data$firearm_flag))

# grouped example
sqf_data %>% 
  group_by(weapon_found_flag, firearm_flag) %>% 
  summarise(N = n()) %>% 
  kable()
```

Note here that even though a `firearm_flag` has a `"Y"` entry and `weapon_found_flag` has a `"N"` entry, this is not necessarily incorrect, as the officer can have identified a firearm without having to carry out a frisk nor a 

First, we deal with these cases of `(null)` separately:

```{r}
# columns with genuinely missing null values
null_1 <- c("ask_for_consent_flg", "consent_given_flg", "suspect_reported_age", "suspect_height", "suspect_weight", "suspect_arrest_offense", "suspect_eye_color", "physical_force_verbal_instruction_flag", "suspect_body_build_type", "suspect_hair_color", "suspect_race_description", "suspect_sex", "stop_location_sector_code", "stop_location_x", "stop_location_y", "suspect_reported_age") 

# pre-clean check
print(unique(sqf_data$ask_for_consent_flg))

# replace these with NAs
sqf_data <- sqf_data %>%
  mutate(across(all_of(null_1), ~ ifelse(. == "(null)", NA, .)))

# post-clean check
print(unique(sqf_data$ask_for_consent_flg))

# columns with null values meaning N
null_2 <- c("firearm_flag", "knife_cutter_flag", "other_weapon_flag") 

# pre-clean check
print(unique(sqf_data$firearm_flag))

# replace these with NAs
sqf_data <- sqf_data %>%
  mutate(across(all_of(null_2), ~ ifelse(. == "(null)", "N", .)))

# post-clean check
print(unique(sqf_data$firearm_flag))
```
  
note some are not so clear like physical force weapon impact, id care identifies etc - like are these selectively not reported or ?

might not matter for prediction question

backround circumstances flags are important

Note, following this cleaning, we now **drop observations** where the suspects race, sex or suspected crime is missing:

```{r}
sqf_data <- sqf_data %>%
  filter(!is.na(suspected_crime_description) & !is.na(suspect_sex) & !is.na(suspect_race_description))

dim(sqf_data)
```

# Exploratory Data Analysis 

## Frisk Status

```{r}
# frisked
sqf_data %>% 
  group_by(frisked_flag) %>% 
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>% 
  arrange(desc(N)) %>% 
  kable(booktabs = TRUE, col.names = c("Suspect Frisked", "N Stops", "% Total Stops"), align = "l")


# 100% stacked version
ggplot(data = sqf_data, aes(x = frisked_flag, fill = suspect_race_description)) +
  geom_bar(position = "fill") +
  coord_flip() +
  theme_minimal() +
  xlab("Suspect Arrested") +
  ylab("% Observations") +
  scale_fill_brewer(type = "qual", palette = "Spectral", name = "Suspect Race") +
  labs(title = "Suspect Frisk Status by Race")

# 100% stacked version
ggplot(data = sqf_data, aes(x = suspect_arrested_flag, fill = suspect_race_description)) +
  geom_bar(position = "fill") +
  coord_flip() +
  facet_wrap(~suspected_crime_description) +
  theme_minimal() +
  xlab("Suspect Arrested") +
  ylab("% Observations") +
  scale_fill_brewer(type = "qual", palette = "Spectral", name = "Suspect Race") +
  labs(title = "Suspect Arrest Status by Race")


```

## Search Status

```{r}
# searched
sqf_data %>%
  group_by(searched_flag) %>%
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>%
  arrange(desc(N)) %>%
  kable(booktabs = TRUE, col.names = c("Suspect Searched", "N Stops", "% Total Stops"), align = "l")

# 100% stacked version
ggplot(data = sqf_data, aes(x = searched_flag, fill = suspect_race_description)) +
  geom_bar(position = "fill") +
  coord_flip() +
  theme_minimal() +
  xlab("Suspect Arrested") +
  ylab("% Observations") +
  scale_fill_brewer(type = "qual", palette = "Spectral", name = "Suspect Race") +
  labs(title = "Suspect Search Status by Race")
```

## Arrest Status

```{r}
sqf_data %>%
  group_by(suspect_arrested_flag) %>%
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>%
  arrange(desc(N)) %>%
  kable(booktabs = TRUE, col.names = c("Suspect Arrested", "N Stops", "% Total Stops"), align = "l")

# plot
ggplot(data = sqf_data, aes(x = suspect_arrested_flag, fill = suspect_race_description)) +
  geom_bar() +
  coord_flip() +
  theme_minimal() +
  xlab("Suspect Arrested") +
  ylab("Number of Observations") +
  scale_fill_brewer(type = "qual", palette = "Spectral", name = "Suspect Race") +
  labs(title = "Suspect Arrest Status by Race")

# 100% stacked version
ggplot(data = sqf_data, aes(x = suspect_arrested_flag, fill = suspect_race_description)) +
  geom_bar(position = "fill") +
  coord_flip() +
  theme_minimal() +
  xlab("Suspect Arrested") +
  ylab("% Observations") +
  scale_fill_brewer(type = "qual", palette = "Spectral", name = "Suspect Race") +
  labs(title = "Suspect Arrest Status by Race")
```

## Physical Force Status

```{r}
```

## Other Univariate Descriptives

```{r}
sqf_data %>%
  group_by(suspected_crime_description) %>%
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>%
  arrange(desc(N)) %>%
  kable(booktabs = TRUE, col.names = c("Suspected Crime", "N Stops", "% Total Stops"), align = "l")


# # suspect sex
sqf_data %>%
  group_by(suspect_sex) %>%
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>%
  arrange(desc(N)) %>%
  kable(booktabs = TRUE, col.names = c("Suspect Sex", "N Stops", "% Total Stops"), align = "l")  

# suspect race
sqf_data %>%
  group_by(suspect_race_description) %>%
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>%
  arrange(desc(N)) %>%
  kable(booktabs = TRUE, col.names = c("Suspect Race", "N Stops", "% Total Stops"), align = "l")  # small amount missing - solution?

# summons offense
sqf_data %>%
  group_by(summons_offense_description) %>%
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>%
  arrange(desc(N)) %>%
  kable(booktabs = TRUE, col.names = c("Summons Offense Description", "N Stops", "% Total Stops"), align = "l")


# suspect concealed weapon
sqf_data %>%
  group_by(suspects_actions_concealed_possession_weapon_flag) %>%
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>%
  arrange(desc(N)) %>%
  kable(booktabs = TRUE, col.names = c("Concealed Possession Weapon", "N Stops", "% Total Stops"), align = "l")





# issuing office rank
sqf_data %>%
  group_by(issuing_officer_rank) %>%
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>%
  arrange(desc(N)) %>%
  kable(booktabs = TRUE, col.names = c("Issuing Officer Rank", "N Stops", "% Total Stops"), align = "l")  


# supervising office rank
sqf_data %>%
  group_by(supervising_officer_rank) %>%
  summarise(N = n(),
            Pc = N / nrow(sqf_data) * 100) %>%
  arrange(desc(N)) %>%
  kable(booktabs = TRUE, col.names = c("Supervising Officer Rank", "N Stops", "% Total Stops"), align = "l")
```

## Weapon Possession

```{r}
sqf_data <- sqf_data %>%
  mutate(weapon_type = case_when(
    firearm_flag == "Y" & knife_cutter_flag == "Y" & other_weapon_flag == "Y" ~ "Firearm, Knife Cutter, and Other Weapon",
    firearm_flag == "Y" & knife_cutter_flag == "Y" ~ "Firearm and Knife Cutter",
    firearm_flag == "Y" & other_weapon_flag == "Y" ~ "Firearm and Other Weapon",
    knife_cutter_flag == "Y" & other_weapon_flag == "Y" ~ "Knife Cutter and Other Weapon",
    firearm_flag == "Y" ~ "Firearm Only",
    knife_cutter_flag == "Y" ~ "Knife Cutter Only",
    other_weapon_flag == "Y" ~ "Other Weapon Only",
    TRUE ~ "No Weapon Found"
  ))

ggplot(sqf_data, aes(x = weapon_found_flag, fill = weapon_type)) +
  geom_bar() +
  labs(
    title = "Weapons Found by Type of Weapon(s)",
    x = "Type of Weapon(s) Found",
    y = "Number of Cases"
  ) +
  theme_minimal() +
  scale_fill_brewer(type = "qual", palette = "Spectral", name = "Weapon Type")
```


* basic grouped tables and plots, cumulative plots

* correlation plots





# Regression Analysis

* state models, assumptions, evaluation criteria blah blah blah
* run + check model diagnostics

# Conclusion
